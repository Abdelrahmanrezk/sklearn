{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Data\n",
    "This is a way to standard your data in a range like [0-1] instead of some features with 1 or 0 and others with 10000 or greater or less and so on\n",
    "\n",
    "also its help the operation on the number to be faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13178.638486557516"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    StandardScaler use standard division\n",
    "    its work as (X - mean(X)) / standard_division(X)\n",
    "    mean(x) sum of X over # number of them\n",
    "'''\n",
    "import numpy as np\n",
    "data = [\n",
    "        [50, 30],\n",
    "        [20, 40], \n",
    "        [1000, 2], \n",
    "        [1, 40000]\n",
    "    ]\n",
    "np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.51462273, -0.57700346],\n",
       "       [-0.58552368, -0.57642577],\n",
       "       [ 1.73057403, -0.57862102],\n",
       "       [-0.63042762,  1.73205025]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    MinMaxScaler divide by max - min\n",
    "    its work as (X - mean(X)) / max - min\n",
    "    \n",
    "'''\n",
    "data = [\n",
    "        [0, 30],\n",
    "        [20, 40], \n",
    "        [40, 2], \n",
    "        [30, 40000]\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 7.00035002e-04],\n",
       "       [5.00000000e-01, 9.50047502e-04],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [7.50000000e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = MinMaxScaler().fit_transform(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Normalizer use sum of each row and divide each number by this sum if norm='l1'\n",
    "    Normalizer use sum of each row number to power of 2 and divide each number by this sqrt of this sum if norm='l2'\n",
    "  Normalizer use max number of each row and divide by it if norm='max'\n",
    "    \n",
    "'''\n",
    "X = [[4, 1, 2, 2],\n",
    "     [1, 3, 9, 3],\n",
    "     [5, 7, 5, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.25      , 0.5       , 0.5       ],\n",
       "       [0.11111111, 0.33333333, 1.        , 0.33333333],\n",
       "       [0.71428571, 1.        , 0.71428571, 0.14285714]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Normalizer(norm='max').fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    the same as Normalizer with norm='max' but with columns\n",
    "    divide each columns number by the max of this column\n",
    "'''\n",
    "X = [[4, 1, 2, 2],\n",
    "     [1, 3, 9, 3],\n",
    "     [5, 7, 5, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8       , 0.14285714, 0.22222222, 0.66666667],\n",
       "       [0.2       , 0.42857143, 1.        , 1.        ],\n",
       "       [1.        , 1.        , 0.55555556, 0.33333333]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = MaxAbsScaler().fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    all values grated than 3 be 1 else be 0 and you choose what is your threshold\n",
    "'''\n",
    "X = [[4, 1, 2, .2],\n",
    "     [1, 3, 9, 3],\n",
    "     [5, 7, 5, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Binarizer(threshold=3).fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    instead of manual features mapping we use PolynomialFeatures function\n",
    "'''\n",
    "X = [[4, 1, 2],\n",
    "     [1, 3, 9],\n",
    "     [5, 7, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  1.,  2.,  4.,  8.,  2.],\n",
       "       [ 1.,  3.,  9.,  3.,  9., 27.],\n",
       "       [ 5.,  7.,  5., 35., 25., 35.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True).fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
